{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "tf.keras.utils.image_dataset_from_directory\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "id": "7l8Go8Knc1Za",
        "outputId": "54879ef4-67b1-47da-dbc9-40a4a879f0fe"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function keras.src.utils.image_dataset_utils.image_dataset_from_directory(directory, labels='inferred', label_mode='int', class_names=None, color_mode='rgb', batch_size=32, image_size=(256, 256), shuffle=True, seed=None, validation_split=None, subset=None, interpolation='bilinear', follow_links=False, crop_to_aspect_ratio=False, pad_to_aspect_ratio=False, data_format=None, verbose=True)>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>keras.src.utils.image_dataset_utils.image_dataset_from_directory</b><br/>def image_dataset_from_directory(directory, labels=&#x27;inferred&#x27;, label_mode=&#x27;int&#x27;, class_names=None, color_mode=&#x27;rgb&#x27;, batch_size=32, image_size=(256, 256), shuffle=True, seed=None, validation_split=None, subset=None, interpolation=&#x27;bilinear&#x27;, follow_links=False, crop_to_aspect_ratio=False, pad_to_aspect_ratio=False, data_format=None, verbose=True)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/keras/src/utils/image_dataset_utils.py</a>Generates a `tf.data.Dataset` from image files in a directory.\n",
              "\n",
              "If your directory structure is:\n",
              "\n",
              "```\n",
              "main_directory/\n",
              "...class_a/\n",
              "......a_image_1.jpg\n",
              "......a_image_2.jpg\n",
              "...class_b/\n",
              "......b_image_1.jpg\n",
              "......b_image_2.jpg\n",
              "```\n",
              "\n",
              "Then calling `image_dataset_from_directory(main_directory,\n",
              "labels=&#x27;inferred&#x27;)` will return a `tf.data.Dataset` that yields batches of\n",
              "images from the subdirectories `class_a` and `class_b`, together with labels\n",
              "0 and 1 (0 corresponding to `class_a` and 1 corresponding to `class_b`).\n",
              "\n",
              "Supported image formats: `.jpeg`, `.jpg`, `.png`, `.bmp`, `.gif`.\n",
              "Animated gifs are truncated to the first frame.\n",
              "\n",
              "Args:\n",
              "    directory: Directory where the data is located.\n",
              "        If `labels` is `&quot;inferred&quot;`, it should contain\n",
              "        subdirectories, each containing images for a class.\n",
              "        Otherwise, the directory structure is ignored.\n",
              "    labels: Either `&quot;inferred&quot;`\n",
              "        (labels are generated from the directory structure),\n",
              "        `None` (no labels),\n",
              "        or a list/tuple of integer labels of the same size as the number of\n",
              "        image files found in the directory. Labels should be sorted\n",
              "        according to the alphanumeric order of the image file paths\n",
              "        (obtained via `os.walk(directory)` in Python).\n",
              "    label_mode: String describing the encoding of `labels`. Options are:\n",
              "        - `&quot;int&quot;`: means that the labels are encoded as integers\n",
              "            (e.g. for `sparse_categorical_crossentropy` loss).\n",
              "        - `&quot;categorical&quot;` means that the labels are\n",
              "            encoded as a categorical vector\n",
              "            (e.g. for `categorical_crossentropy` loss).\n",
              "        - `&quot;binary&quot;` means that the labels (there can be only 2)\n",
              "            are encoded as `float32` scalars with values 0 or 1\n",
              "            (e.g. for `binary_crossentropy`).\n",
              "        - `None` (no labels).\n",
              "    class_names: Only valid if `labels` is `&quot;inferred&quot;`.\n",
              "        This is the explicit list of class names\n",
              "        (must match names of subdirectories). Used to control the order\n",
              "        of the classes (otherwise alphanumerical order is used).\n",
              "    color_mode: One of `&quot;grayscale&quot;`, `&quot;rgb&quot;`, `&quot;rgba&quot;`.\n",
              "        Whether the images will be converted to\n",
              "        have 1, 3, or 4 channels. Defaults to `&quot;rgb&quot;`.\n",
              "    batch_size: Size of the batches of data. Defaults to 32.\n",
              "        If `None`, the data will not be batched\n",
              "        (the dataset will yield individual samples).\n",
              "    image_size: Size to resize images to after they are read from disk,\n",
              "        specified as `(height, width)`.\n",
              "        Since the pipeline processes batches of images that must all have\n",
              "        the same size, this must be provided. Defaults to `(256, 256)`.\n",
              "    shuffle: Whether to shuffle the data. Defaults to `True`.\n",
              "        If set to `False`, sorts the data in alphanumeric order.\n",
              "    seed: Optional random seed for shuffling and transformations.\n",
              "    validation_split: Optional float between 0 and 1,\n",
              "        fraction of data to reserve for validation.\n",
              "    subset: Subset of the data to return.\n",
              "        One of `&quot;training&quot;`, `&quot;validation&quot;`, or `&quot;both&quot;`.\n",
              "        Only used if `validation_split` is set.\n",
              "        When `subset=&quot;both&quot;`, the utility returns a tuple of two datasets\n",
              "        (the training and validation datasets respectively).\n",
              "    interpolation: String, the interpolation method used when\n",
              "        resizing images.\n",
              "        Supports `&quot;bilinear&quot;`, `&quot;nearest&quot;`, `&quot;bicubic&quot;`, `&quot;area&quot;`,\n",
              "        `&quot;lanczos3&quot;`, `&quot;lanczos5&quot;`, `&quot;gaussian&quot;`, `&quot;mitchellcubic&quot;`.\n",
              "        Defaults to `&quot;bilinear&quot;`.\n",
              "    follow_links: Whether to visit subdirectories pointed to by symlinks.\n",
              "        Defaults to `False`.\n",
              "    crop_to_aspect_ratio: If `True`, resize the images without aspect\n",
              "        ratio distortion. When the original aspect ratio differs from the\n",
              "        target aspect ratio, the output image will be cropped so as to\n",
              "        return the largest possible window in the image\n",
              "        (of size `image_size`) that matches the target aspect ratio. By\n",
              "        default (`crop_to_aspect_ratio=False`), aspect ratio may not be\n",
              "        preserved.\n",
              "    pad_to_aspect_ratio: If `True`, resize the images without aspect\n",
              "        ratio distortion. When the original aspect ratio differs from the\n",
              "        target aspect ratio, the output image will be padded so as to\n",
              "        return the largest possible window in the image\n",
              "        (of size `image_size`) that matches the target aspect ratio. By\n",
              "        default (`pad_to_aspect_ratio=False`), aspect ratio may not be\n",
              "        preserved.\n",
              "    data_format: If None uses keras.config.image_data_format()\n",
              "        otherwise either &#x27;channel_last&#x27; or &#x27;channel_first&#x27;.\n",
              "    verbose: Whether to display number information on classes and\n",
              "        number of files found. Defaults to `True`.\n",
              "\n",
              "Returns:\n",
              "\n",
              "A `tf.data.Dataset` object.\n",
              "\n",
              "- If `label_mode` is `None`, it yields `float32` tensors of shape\n",
              "    `(batch_size, image_size[0], image_size[1], num_channels)`,\n",
              "    encoding images (see below for rules regarding `num_channels`).\n",
              "- Otherwise, it yields a tuple `(images, labels)`, where `images` has\n",
              "    shape `(batch_size, image_size[0], image_size[1], num_channels)`,\n",
              "    and `labels` follows the format described below.\n",
              "\n",
              "Rules regarding labels format:\n",
              "\n",
              "- if `label_mode` is `&quot;int&quot;`, the labels are an `int32` tensor of shape\n",
              "    `(batch_size,)`.\n",
              "- if `label_mode` is `&quot;binary&quot;`, the labels are a `float32` tensor of\n",
              "    1s and 0s of shape `(batch_size, 1)`.\n",
              "- if `label_mode` is `&quot;categorical&quot;`, the labels are a `float32` tensor\n",
              "    of shape `(batch_size, num_classes)`, representing a one-hot\n",
              "    encoding of the class index.\n",
              "\n",
              "Rules regarding number of channels in the yielded images:\n",
              "\n",
              "- if `color_mode` is `&quot;grayscale&quot;`,\n",
              "    there&#x27;s 1 channel in the image tensors.\n",
              "- if `color_mode` is `&quot;rgb&quot;`,\n",
              "    there are 3 channels in the image tensors.\n",
              "- if `color_mode` is `&quot;rgba&quot;`,\n",
              "    there are 4 channels in the image tensors.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 12);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "SUt-tBHVJP4-"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "dataset_url=\"https://www.kaggle.com/datasets/kritikseth/fruit-and-vegetable-image-recognition\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a machine learning model to classify images in to two categories\n",
        "# fruits and vegetables\n",
        "classes=os.listdir(dataset_url)\n",
        "image_paths=[]\n",
        "for cls in classes:\n",
        "    class_path=os.path.join(dataset_url,cls)\n",
        "    images=os.listdir(class_path)\n",
        "    for image in images:\n",
        "        image_paths.append(os.path.join(class_path,image))\n",
        "random_images=random.sample(image_paths,15)\n",
        "for image in random_images:\n",
        "    img=mpimg.imread(image)\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "IKQy_KJIcz4Y",
        "outputId": "4d488562-973b-4fc9-b410-3d489ec580ac"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'https://www.kaggle.com/datasets/kritikseth/fruit-and-vegetable-image-recognition'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-49edcef36a6a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# create a machine learning model to classify images in to two categories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# fruits and vegetables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'https://www.kaggle.com/datasets/kritikseth/fruit-and-vegetable-image-recognition'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "ASwo-kqhVJpn",
        "outputId": "68e45e4b-24e7-4ad2-da3e-cca7f2bd96ac"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "Could not find directory /content/images",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-038592cff27b>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimage_directory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/images'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_dataset_from_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/image_dataset_utils.py\u001b[0m in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, pad_to_aspect_ratio, data_format, verbose)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     image_paths, labels, class_names = dataset_utils.index_directory(\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/dataset_utils.py\u001b[0m in \u001b[0;36mindex_directory\u001b[0;34m(directory, labels, formats, class_names, shuffle, seed, follow_links, verbose)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"inferred\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0msubdirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mlist_directory_v2\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    766\u001b[0m   \"\"\"\n\u001b[1;32m    767\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m     raise errors.NotFoundError(\n\u001b[0m\u001b[1;32m    769\u001b[0m         \u001b[0mnode_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0mop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Could not find directory /content/images"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "yhERsVPHKRzQ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Trdd8ETdUdwf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}